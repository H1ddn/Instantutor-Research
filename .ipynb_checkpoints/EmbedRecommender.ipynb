{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae33e0fb-25cd-405d-ab7d-419fcbbb34c1",
   "metadata": {},
   "source": [
    "Developing an embedding based recommender with collaborative filtering for scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3315fa1e-5beb-48b6-be6b-8851be4d67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import string\n",
    "import argparse\n",
    "import inflect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as du\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils import data\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1bcd8f-0aa2-4b80-82d8-b390152c639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data to a sparse matrix(Mostly 0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb347221-8ca0-4b97-9123-99f198590568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A two-tower model for candidate generation(selecting a more representative, smaller sample) and re-ranking(ranking these samples).\n",
    "#This involves using encoder and decoder.\n",
    "#Computing the dot product of these two embeddings allows us to determine whether the item and user are a good match(high dot product)\n",
    "#When training, we need to train on both positive and randomly generated negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7192d9-0d30-48e3-8994-336659ac5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    '''\n",
    "    This class will encode user information into a learnable embedding\n",
    "    It does this by taking user information(time zone, subject) and encoding it into a fixed size vector.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(UserEncoder, self).__init__()\n",
    "    \n",
    "    def forward(self):\n",
    "        #to be implemented\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6e6d46-79e3-43c7-9900-49a289ce459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemEncoder(nn.Module):\n",
    "    '''\n",
    "    This class encodes item information into a learnable embedding\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(ItemEncoder, self).__init__()\n",
    "        \n",
    "    def forward(self):\n",
    "        #to be implemented\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e913fecc-3633-44b7-9304-5f539934fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating positive and negative pairs:\n",
    "    #For each user, the positive pairs are the user and their previously used tutors while negatives are randomly sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14861fe9-a637-43d3-9aec-f6bba98a0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have an embedding for user tutors\n",
    "#We feed these along with the desired subject/time into a RNN\n",
    "#Take the Logits and Compute Softmax Loss, then backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3add821-2731-457f-b620-c4e1b7d3c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        #Use 3 convolutional layers, each with a different kernel\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, 1)\n",
    "        self.conv2 = nn.Conv1d(in_ch, out_ch, 2)\n",
    "        self.conv3 = nn.Conv1d(in_ch, out_ch, 4)\n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        #to be implemented\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25858457-a62c-4779-a59a-a3a2045abe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_ft, in_dim, hidden_ft, hidden_dim, out_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        #Define the Recurrent Neural Network. \n",
    "        self.rec = nn.LSTM(in_ft, hidden_ft)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "    \n",
    "    def forward(self, representation):\n",
    "        '''\n",
    "        Feed the given representation into an LSTM and pass it through an MLP\n",
    "        '''\n",
    "        \n",
    "        out = self.rec(representation)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a5c5e4-10f0-410a-b00b-bb31cfc8e486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Recommender(nn.Module):\n",
    "    '''\n",
    "    This class holds an embedding layer from which it will obtain representations of provided tutors.\n",
    "    It also holds an MLP(RNN) which will be called on the obtained representation.\n",
    "    '''\n",
    "    def __init__(self, num_embed, embed_dim, in_ft, in_dim, hidden_ft, hidden_dim, out_dim):\n",
    "        super(Recommender, self).__init__()\n",
    "        \n",
    "        #Define our embedding layer\n",
    "        self.representation = nn.Embedding(num_embed, embed_dim)\n",
    "        \n",
    "        #Define our RNN\n",
    "        self.RNN = RNN(in_ft, in_dim, hidden_ft, hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, tutors):\n",
    "        \n",
    "        #obtain representations for the input tutors from the embedding.\n",
    "        tutor_rep = self.representation(tutors)\n",
    "        \n",
    "        #feed our representations into the RNN\n",
    "        output = self.RNN(tutor_rep)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a451a755-b4bf-4eea-8e45-10de89b09e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Word2Vec,self).__init__()\n",
    "    \n",
    "    def forward(self):\n",
    "        #to be implemented\n",
    "        return\n",
    "    \n",
    "    def neg_sampling(self):\n",
    "        #to be implemented\n",
    "        return\n",
    "        \n",
    "    def pos_sampling(self):\n",
    "        #to be implemented\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ebe8e-fd32-4949-a638-45caf8f8695f",
   "metadata": {},
   "source": [
    "Once we have our embeddings, we can recommend new users their k nearest neighbors based on their embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

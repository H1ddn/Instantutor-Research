{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0470c3-2781-40ee-8a12-c991403be1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import string\n",
    "import argparse\n",
    "import inflect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as du\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from torch.utils import data\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff570b-7b57-4c83-a705-64aae28ce056",
   "metadata": {},
   "source": [
    "Obtain text from a user's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bc66c9-251e-486e-a21f-9ee04b6f8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is sample text. Will be used as an intermediate process during the running of the recommender model.\n",
    "sample_text = \"How do I find the determinant of a 3x3 matrix?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45118ea-2c13-46ea-bee2-9ebfabf8075f",
   "metadata": {},
   "source": [
    "Preprocess the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a10bb2-f80f-46d0-bcf8-1303e2eac27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do i find the determinant of a 3x3 matrix?\n"
     ]
    }
   ],
   "source": [
    "#First we standardize sentences by removing punctuation, uniforming white spaces and lowercasing all words.\n",
    "\n",
    "s_words = sample_text.lower().split()\n",
    "strd_text = \" \".join(s_words)\n",
    "print(strd_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a84a32-abf8-4db7-81ed-157b8c67e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do i find the determinant of a 3x3 matrix\n"
     ]
    }
   ],
   "source": [
    "#Next, we remove all punctuation\n",
    "strd_text = strd_text.translate(str.maketrans('','', string.punctuation))\n",
    "print(strd_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ca74b-3de7-4a6e-b8b9-6049c601118c",
   "metadata": {},
   "source": [
    "Optional: We can convert numbers to words and weigh them so that they will lean the sentence slightly towards being interpreted as math related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ef10cf-51c0-4c8d-b488-83117c2af161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do i find the determinant of a 3x3 matrix\n"
     ]
    }
   ],
   "source": [
    "#Convert all numbers to words (ex: 3 -> three)\n",
    "p = inflect.engine()\n",
    "\n",
    "#split the words to parse for numbers, create a new array to store words\n",
    "old_string = strd_text.split()\n",
    "new_string = []\n",
    "\n",
    "for word in old_string:\n",
    "    if word.isdigit():\n",
    "        converted = p.number_to_words(word)\n",
    "        new_string.append(converted)\n",
    "    else:\n",
    "        new_string.append(word)\n",
    "        \n",
    "strd_text = \" \".join(new_string)\n",
    "\n",
    "print(strd_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490a078-c6d8-459e-95f6-68241bd048c0",
   "metadata": {},
   "source": [
    "Clearly this did not work when we identified the dimensions of a matrix. This will need to be fixed in the future. Arguably, we could have treated that as a meaningless word and removed it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6df7277-68c3-4037-8854-9ec7707f6b6a",
   "metadata": {},
   "source": [
    "Next, we want to remove any filler words that do not provide much meaning to a sentence outside of grammatical purposes. These words are known as stop words, such as \"a\" or \"the\". We will likely not need any question related words such as how, why, where as well, since the request should imply a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eaeedc7-3eea-4a23-9ebb-ff1e5c1bb8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find', 'determinant', '3x3', 'matrix']\n"
     ]
    }
   ],
   "source": [
    "#remove stop words from the sentence.(We need to define a list of stop words, but we can simply obtain them from nltk.\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "word_tokens = word_tokenize(strd_text)\n",
    "strd_text = [word for word in word_tokens if word not in stop_words]\n",
    "print(strd_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f859468-8d50-40de-b555-1b57d5b7ae8c",
   "metadata": {},
   "source": [
    "Optional: \n",
    "Next, we will use stemming to obtain the root form of each \"meaningful\" word. Stemming may not give actual words, but it is much faster/more computationally efficient than lemmatizing, which guarantees actual words. It is also not mandatory, although it does reduce the size of necessary language dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13ff1b3d-8b12-46e4-95d9-faa4a7e51450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find', 'determin', '3x3', 'matrix']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stems = [stemmer.stem(word) for word in strd_text]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf18ae-2cff-435a-a826-16b5500116be",
   "metadata": {},
   "source": [
    "Now that we have preprocessed the sentence, we must vectorize it so that machine learning can be done on the sentence. For this process we will use word embeddings. The word2vec word embedding method will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74324f0-bac7-49a1-b649-b3423d495e64",
   "metadata": {},
   "source": [
    "For the word2vec method, we first need to determine a window size, for now, let this be win_size = 5. This means for each target word, we will take two words from both the left and right side to be the context. For sequential words not separated by spaces, we may use offsets but this is not necessary since we have tokenized sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d4e16dd-0d72-48f4-ac7e-e7b29a3beab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all context words for each target in a sentence. \n",
    "#For the sake of scalability, we will use indicies to represent words and have a mapping of words to indexes and the reverse\n",
    "#Normally while training, we are given a large amount of text to train on, so this process may take up to hours.\n",
    "\n",
    "win_size = 5\n",
    "\n",
    "word_to_ind = {}\n",
    "ind_to_word = []\n",
    "\n",
    "#first count the frequency of each word in the sentence\n",
    "word_freq = {}\n",
    "\n",
    "for word in strd_text:\n",
    "    word_freq[word] = word_freq.get(word,0) + 1\n",
    "        \n",
    "text_len = len(strd_text)\n",
    "#then map each word to an index and each index to a word\n",
    "o = 0\n",
    "for word in word_freq.keys():\n",
    "    ind_to_word.append(word)\n",
    "    word_to_ind[word] = o\n",
    "    o += 1\n",
    "\n",
    "half_win = win_size//2\n",
    "\n",
    "context = [[] for word in ind_to_word]\n",
    "\n",
    "#we use np.clip so that we do not go out of bounds\n",
    "for i in range(text_len):\n",
    "    #treat each word as a target\n",
    "    targ_word = strd_text[i]\n",
    "    \n",
    "    for j in range(np.clip(i-half_win, 0, i), i):\n",
    "        context[word_to_ind[targ_word]].append(word_to_ind[strd_text[j]])\n",
    "    for k in range(i, np.clip(i+half_win, i, text_len)):\n",
    "        context[word_to_ind[targ_word]].append(word_to_ind[strd_text[k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac850372-1cd7-4d3f-82f6-5ebdfecad888",
   "metadata": {},
   "source": [
    "Define a custom collate function to pad zeroes since our words may have different amounts of context and therefore, different number of pairs.\n",
    "The collate function simply stacks the get_item values for each batch item. This will be provided to our dataloader because the default collate function cannot handle tensors of different lengths, which is very common with sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d7aa44-1806-42cf-8f51-43281636a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_func(batch):\n",
    "    \n",
    "    len1 = [len(item[1]) for item in batch]\n",
    "    dsum = [item[3] for item in batch]\n",
    "    \n",
    "    d = np.sum(dsum)\n",
    "    maxlen = max(len1)\n",
    "    \n",
    "    c_o = batch[0][2]\n",
    "    \n",
    "    t_o = torch.zeros(maxlen)\n",
    "    w_o = torch.zeros(maxlen)\n",
    "    \n",
    "    for item in batch:\n",
    "        c = item[2]\n",
    "        c_len = c.size(dim=0)\n",
    "        t_out = torch.zeros(maxlen)\n",
    "        w_out = torch.zeros(maxlen)\n",
    "        t_out[:c_len] = item[0]\n",
    "        w_out[:c_len] = item[1]\n",
    "        #torch.vstack((c_o, c))\n",
    "        torch.at_least_2d(t_out)\n",
    "        torch.at_least_2d(w_out)\n",
    "        torch.vstack((t_o, t_out.long()), axis = 1)\n",
    "        torch.vstack((w_o, w_out.long()), axis = 1)\n",
    "    \n",
    "    return t_o.long(), w_o.long(), c_o.long(), d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b761afd4-ce25-4fc5-916c-210dd221fa42",
   "metadata": {},
   "source": [
    "Define our word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d74cff-3a17-407f-af61-34e7c968872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class word2vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(word2vec, self).__init__()\n",
    "        \n",
    "        #define the two layers\n",
    "        self.Target = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.Context = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, targets, contexts, len1):\n",
    "        #look up embeddings for the given targets and contexts\n",
    "        target_w = self.t(targets)\n",
    "        context_w = self.c(contexts)\n",
    "        \n",
    "        #find the dot product between corresponding pairs\n",
    "        dp = torch.sum(torch.mul(target_w, context_w), dim = 1)\n",
    "        \n",
    "        return dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505617f-4ca9-403a-ae6d-c304ef392fc8",
   "metadata": {},
   "source": [
    "Define our dataset model, through which we will send sequences in batches through dataloader for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f9d49d2-d3a8-424f-ba1d-72793c8844b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class sentence_Dataset(Dataset):\n",
    "    def __init__(self, w_2in, in2_w, context, prob_dist, q):       \n",
    "        super(sentence_Dataset, self).__init__()\n",
    "        \n",
    "        self.w_2in = w_2in\n",
    "        self.in_2w = in_2w\n",
    "        self.context = context\n",
    "        self.prob_dist = prob_dist\n",
    "        self.q = q\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.in_w)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #to be defined\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ddd7d8-7ab5-4e9b-8609-89f3fa9800c9",
   "metadata": {},
   "source": [
    "Define our training parameters, the batch_size, the learning rate, the number of epochs, and the embedding dimensions. For now, we will let embedding dim be 2 and batch size be 1 since our dataset is tiny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d22c8b-829b-4646-bc85-86ad1307fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "epochs = 3\n",
    "lr = 0.1\n",
    "batch_size = 1\n",
    "embedding_dim = 2\n",
    "\n",
    "#Use a GPU if possible.\n",
    "device = f'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d715ae9-3be1-4d2d-969b-efcca9dbfa8a",
   "metadata": {},
   "source": [
    "BERT Model\n",
    "When we are training the bert model, we must first tokenize our sentences, ideally into integer representations to save space. We can then convert any sequences we are trying to evaluate and convert them back after the model is finished evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddcfece4-1e54-463e-89ee-6d14bf9593f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A standard MLP with one hidden layer.\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(FNN, self).__init__()\n",
    "        \n",
    "        #two fully connected layers\n",
    "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # compute output of fc1, and apply relu activation\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        #Apply relu activation\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # compute output layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe36c0c-172f-423a-a0d1-6db3bd8be212",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_embeddings, num_heads, d_model, in_dim, device):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        #Define our self attention\n",
    "        self.mha = torch.nn.MultiheadAttention(num_embeddings, num_heads, dropout=0.0, device = device)\n",
    "        \n",
    "        self.rep_dim = d_model//num_heads\n",
    "        #Define query, key and value representation projections of the sentence\n",
    "        self.query = nn.Linear(d_model, self.rep_dim)\n",
    "        self.key = nn.Linear(d_model, self.rep_dim)\n",
    "        self.value = nn.Linear(d_model, self.rep_dim)\n",
    "        \n",
    "        #Linear Transformation of multi head attention if necessary\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm((in_dim, d_model))\n",
    "        self.ffn = FNN(d_model, d_model, d_model)\n",
    "        self.ln2 = nn.LayerNorm((in_dim, d_model))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Project the sentence into query, key, and value\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "        \n",
    "        #Send the query key and value to the multi-head-attention\n",
    "        output = self.mha(query, key, value, need_weights = False)\n",
    "        \n",
    "        #We may need to project the output into the correct space.\n",
    "        \n",
    "        #Do residual connection\n",
    "        r_x1 = self.ln1(x + r_x)\n",
    "        \n",
    "        #Feed r_x1 into the feed forward network\n",
    "        r_x2 = self.ffn(r_x1)\n",
    "        \n",
    "        #Do the second residual connection\n",
    "        r_x3 = self.ln2(r_x1 + r_x2)\n",
    "        \n",
    "        return r_x3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981fe91-bbc8-41db-b29d-b43d1e08d41a",
   "metadata": {},
   "source": [
    "For training BERT, we would ideally train for >20 epochs with >8 layers. Each epoch should take at least an hour depending on dataset size. Optimization will need to be done on the code in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a085947-040a-40ca-ab90-f36cb66b9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, num_heads, num_embeddings, model_dim, in_dim, layers, device):\n",
    "        super(BERT, self).__init__()\n",
    "        \n",
    "        self.num_embeddings = num_embeddings\n",
    "        \n",
    "        #padding_idx is 0 so that the cls token will not be trained\n",
    "        self.embeddings = nn.Embedding(num_embeddings, model_dim, padding_idx = 0)\n",
    "        \n",
    "        #Initialize the Transformer Layers\n",
    "        self.transblock = nn.ModuleList([Transformer(num_embeddings, num_heads, model_dim, in_dim, device) for i in range(layers)])\n",
    "        \n",
    "        self.final = nn.Linear(model_dim, num_embeddings)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        #Obtain embedding of the sentence\n",
    "        embed = self.embedding(sentence)\n",
    "        \n",
    "        #run the transformer layers\n",
    "        for layers in self.transblock:\n",
    "            embed = layers(embed)\n",
    "            \n",
    "        #Apply a final Linear Transformation if necessary.\n",
    "        output = self.final(embed)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "670fcb04-855b-41ce-8bd8-9a96cf312eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (embeddings): Embedding(8, 64, padding_idx=0)\n",
       "  (transblock): ModuleList(\n",
       "    (0): Transformer(\n",
       "      (mha): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "      )\n",
       "      (query): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (key): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (value): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (ln1): LayerNorm((8, 64), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FNN(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((8, 64), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (final): Linear(in_features=64, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training parameters, should be adjusted in the future\n",
    "bert_learning_rate = 0.001\n",
    "bert_epochs = 3\n",
    "num_heads = 4\n",
    "num_layers = 1\n",
    "model_dim = 64\n",
    "\n",
    "#These Parameters Still have to be decided on.\n",
    "bert_embedding_dim = 8\n",
    "bert_in_dim = 8\n",
    "\n",
    "#Initialize the bert model\n",
    "Bert = BERT(num_heads, bert_embedding_dim, model_dim, bert_in_dim, num_layers, device)\n",
    "\n",
    "#Send bert to the device and begin training.\n",
    "Bert = Bert.to(device)\n",
    "Bert.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21f1ce-41b2-4572-8f67-4962bf2eae1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

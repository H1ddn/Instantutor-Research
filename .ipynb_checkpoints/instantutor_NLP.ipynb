{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585ab6fc-c56a-4eff-b025-0d73db1d4215",
   "metadata": {},
   "source": [
    "Currently, only the preprocessing has been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8d274d-7c70-4ba2-ae95-88ca30f4d384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import inflect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#to run this code the user must run nltk.download(\"packagename\"), where package name can be stopwords or punkt\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff570b-7b57-4c83-a705-64aae28ce056",
   "metadata": {},
   "source": [
    "Obtain text from a user's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bc66c9-251e-486e-a21f-9ee04b6f8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is sample text. Will be used as an intermediate process during the running of the recommender model.\n",
    "sample_text = \"How do I find the determinant of a 3x3 matrix?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45118ea-2c13-46ea-bee2-9ebfabf8075f",
   "metadata": {},
   "source": [
    "Preprocess the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a10bb2-f80f-46d0-bcf8-1303e2eac27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do i find the determinant of a 3x3 matrix?\n"
     ]
    }
   ],
   "source": [
    "#First we standardize sentences by removing punctuation, uniforming white spaces and lowercasing all words.\n",
    "\n",
    "s_words = sample_text.lower().split()\n",
    "strd_text = \" \".join(s_words)\n",
    "print(strd_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a84a32-abf8-4db7-81ed-157b8c67e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do i find the determinant of a 3x3 matrix\n"
     ]
    }
   ],
   "source": [
    "#Next, we remove all punctuation\n",
    "strd_text = strd_text.translate(str.maketrans('','', string.punctuation))\n",
    "print(strd_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ca74b-3de7-4a6e-b8b9-6049c601118c",
   "metadata": {},
   "source": [
    "Optional: We can convert numbers to words and weigh them so that they will lean the sentence slightly towards being interpreted as math related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ef10cf-51c0-4c8d-b488-83117c2af161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do i find the determinant of a 3x3 matrix\n"
     ]
    }
   ],
   "source": [
    "#Convert all numbers to words (ex: 3 -> three)\n",
    "p = inflect.engine()\n",
    "\n",
    "#split the words to parse for numbers, create a new array to store words\n",
    "old_string = strd_text.split()\n",
    "new_string = []\n",
    "\n",
    "for word in old_string:\n",
    "    if word.isdigit():\n",
    "        converted = p.number_to_words(word)\n",
    "        new_string.append(converted)\n",
    "    else:\n",
    "        new_string.append(word)\n",
    "        \n",
    "strd_text = \" \".join(new_string)\n",
    "\n",
    "print(strd_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490a078-c6d8-459e-95f6-68241bd048c0",
   "metadata": {},
   "source": [
    "Clearly this did not work when we identified the dimensions of a matrix. This will need to be fixed in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6df7277-68c3-4037-8854-9ec7707f6b6a",
   "metadata": {},
   "source": [
    "Next, we want to remove any filler words that do not provide much meaning to a sentence outside of grammatical purposes. These words are known as stop words, such as \"a\" or \"the\". We will likely not need any question related words such as how, why, where as well, since the request should imply a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eaeedc7-3eea-4a23-9ebb-ff1e5c1bb8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find', 'determinant', '3x3', 'matrix']\n"
     ]
    }
   ],
   "source": [
    "#remove stop words from the sentence.(We need to define a list of stop words, but we can simply obtain them from nltk.\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "word_tokens = word_tokenize(strd_text)\n",
    "strd_text = [word for word in word_tokens if word not in stop_words]\n",
    "print(strd_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f859468-8d50-40de-b555-1b57d5b7ae8c",
   "metadata": {},
   "source": [
    "Optional: \n",
    "Next, we will use stemming to obtain the root form of each \"meaningful\" word. Stemming may not give actual words, but it is much faster/more computationally efficient than lemmatizing, which guarantees actual words. It is also not mandatory, although it does reduce the size of necessary language dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13ff1b3d-8b12-46e4-95d9-faa4a7e51450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find', 'determin', '3x3', 'matrix']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stems = [stemmer.stem(word) for word in strd_text]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf18ae-2cff-435a-a826-16b5500116be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
